# ショート動画設計図生成プロジェクト設計書

## プロジェクト概要

単一の動画ファイルを入力として、ショート動画作成用の設計図（企画書）を自動生成するPythonプロジェクト。

### 主要機能
- 動画ファイルからWhisper APIを使用した音声文字起こし
- ChatGPT APIを使用したショート動画企画書の生成
- 切り抜き箇所（開始・終了時刻）、タイトル案、キャプション案を含むマークダウン形式の企画書出力
- SRT形式の字幕ファイル出力

### 技術要件
- Python 3.8+
- Poetry（パッケージ管理）
- mypy（型チェック）
- 依存性注入（DI）パターンの採用
- ローカルCLIとして動作

## システムアーキテクチャ

### 全体構成図

```mermaid
graph TD
    A[main.py] --> B[GenerateShortDraftUsecase]
    B --> C[DraftGenerator]
    C --> D[WhisperClient]
    C --> E[ChatGPTClient]
    C --> F[PromptBuilder]

    D --> G[Whisper API]
    E --> H[ChatGPT API]

    I[input/input.mp4] --> B
    B --> J[output/draft.md]
    B --> K[output/subtitle.srt]

    L[.env] --> D
    L --> E
```

### レイヤー構成

1. **Presentation Layer** (`main.py`)
   - CLIインターフェース
   - 引数解析とバリデーション

2. **Application Layer** (`usecases/`)
   - ビジネスロジックの調整
   - 各サービスの呼び出し順序制御

3. **Domain Layer** (`service/`)
   - コアビジネスロジック
   - データ変換処理

4. **Infrastructure Layer** (`clients/`, `builders/`)
   - 外部API連携
   - プロンプト生成

## クラス設計

### 1. GenerateShortDraftUsecase
```python
class GenerateShortDraftUsecase:
    def __init__(self, draft_generator: DraftGenerator) -> None
    def execute(self, video_path: str, output_dir: str) -> GenerateResult
```

**責務**:
- ショート動画企画書生成の全体フローを制御
- 入力検証と出力ファイル管理

### 2. DraftGenerator
```python
class DraftGenerator:
    def __init__(
        self,
        whisper_client: WhisperClient,
        chatgpt_client: ChatGPTClient,
        prompt_builder: PromptBuilder
    ) -> None
    def generate_draft(self, video_path: str) -> DraftResult
```

**責務**:
- 音声文字起こしとAI企画書生成の調整
- 中間データの管理

### 3. WhisperClient
```python
class WhisperClient:
    def __init__(self, api_key: str) -> None
    def transcribe(self, audio_path: str) -> TranscriptionResult
```

**責務**:
- Whisper APIとの通信
- 音声ファイルの文字起こし
- タイムスタンプ付きテキストの生成

### 4. ChatGPTClient
```python
class ChatGPTClient:
    def __init__(self, api_key: str, model: str = "gpt-4") -> None
    def generate_draft(self, prompt: str) -> str
```

**責務**:
- ChatGPT APIとの通信
- 企画書テキストの生成

### 5. PromptBuilder
```python
class PromptBuilder:
    def build_draft_prompt(self, transcription: TranscriptionResult) -> str
```

**責務**:
- ChatGPT用プロンプトの構築
- 文字起こし結果の整形

## データ構造

### TranscriptionResult
```python
@dataclass
class TranscriptionSegment:
    start_time: float
    end_time: float
    text: str

@dataclass
class TranscriptionResult:
    segments: List[TranscriptionSegment]
    full_text: str
```

### DraftResult
```python
@dataclass
class ShortVideoProposal:
    title: str
    start_time: float
    end_time: float
    caption: str
    key_points: List[str]

@dataclass
class DraftResult:
    proposals: List[ShortVideoProposal]
    original_transcription: TranscriptionResult
```

### GenerateResult
```python
@dataclass
class GenerateResult:
    draft_file_path: str
    subtitle_file_path: str
    success: bool
    error_message: Optional[str] = None
```

## 処理フロー詳細

### メイン処理フロー
1. **入力検証** (`main.py`)
   - 動画ファイルの存在確認
   - 出力ディレクトリの作成

2. **音声抽出・文字起こし** (`WhisperClient`)
   - 動画から音声抽出（ffmpeg使用）
   - Whisper APIで文字起こし実行
   - タイムスタンプ付きセグメント生成

3. **企画書生成** (`ChatGPTClient` + `PromptBuilder`)
   - 文字起こし結果からプロンプト構築
   - ChatGPT APIで企画書生成
   - 構造化データへの変換

4. **ファイル出力** (`DraftGenerator`)
   - マークダウン形式の企画書出力
   - SRT形式の字幕ファイル出力

### エラーハンドリング
- API呼び出し失敗時のリトライ機能
- 不正な動画ファイル形式の検出
- ネットワークエラーの適切な処理

## ディレクトリ構造

```
shortmovie-draft-generator2/
├── pyproject.toml
├── README.md
├── .env.example
├── .gitignore
├── src/
│   ├── __init__.py
│   ├── main.py
│   ├── usecases/
│   │   ├── __init__.py
│   │   └── generate_short_draft_usecase.py
│   ├── service/
│   │   ├── __init__.py
│   │   └── draft_generator.py
│   ├── clients/
│   │   ├── __init__.py
│   │   ├── chatgpt_client.py
│   │   └── whisper_client.py
│   └── builders/
│       ├── __init__.py
│       └── prompt_builder.py
├── tests/
│   ├── __init__.py
│   ├── test_usecases/
│   ├── test_service/
│   ├── test_clients/
│   └── test_builders/
├── input/
│   ├── .gitkeep
│   └── input.mp4 (gitignore)
├── intermediate/
│   ├── .gitkeep
│   ├── audio.wav (gitignore)
│   └── transcription.json (gitignore)
└── output/
    ├── .gitkeep
    ├── draft.md (gitignore)
    └── subtitle.srt (gitignore)
```

## 設定管理

### 環境変数 (.env)
```
OPENAI_API_KEY=your_openai_api_key_here
CHATGPT_MODEL=gpt-4
WHISPER_MODEL=whisper-1
```

### 依存関係 (pyproject.toml)
```toml
[tool.poetry.dependencies]
python = "^3.8"
openai = "^1.0.0"
python-dotenv = "^1.0.0"
click = "^8.0.0"
ffmpeg-python = "^0.2.0"

[tool.poetry.group.dev.dependencies]
mypy = "^1.0.0"
pytest = "^7.0.0"
black = "^23.0.0"
flake8 = "^6.0.0"
```

## 出力形式

### 企画書 (draft.md)
```markdown
# ショート動画企画書

## 動画情報
- 元動画: input.mp4
- 生成日時: 2025-01-09 23:53:00

## 提案1: [タイトル]
- **開始時刻**: 00:01:30
- **終了時刻**: 00:02:00
- **キャプション**: [キャプション内容]
- **キーポイント**:
  - ポイント1
  - ポイント2

## 提案2: [タイトル]
...
```

### 字幕ファイル (subtitle.srt)
```
1
00:00:00,000 --> 00:00:03,000
[文字起こし内容1]

2
00:00:03,000 --> 00:00:06,000
[文字起こし内容2]
```

## 将来拡張への考慮

### Google Drive連携
- `clients/`に`GoogleDriveClient`を追加
- 入出力パスをGoogle Drive URLに対応

### Cloud Functions / GitHub Actions対応
- 環境変数による設定切り替え
- ログ出力の標準化
- バッチ処理モードの追加

## 依存性注入の実装

### DIコンテナ
```python
class DIContainer:
    def __init__(self) -> None:
        self._whisper_client = WhisperClient(os.getenv("OPENAI_API_KEY"))
        self._chatgpt_client = ChatGPTClient(os.getenv("OPENAI_API_KEY"))
        self._prompt_builder = PromptBuilder()
        self._draft_generator = DraftGenerator(
            self._whisper_client,
            self._chatgpt_client,
            self._prompt_builder
        )
        self._usecase = GenerateShortDraftUsecase(self._draft_generator)

    def get_usecase(self) -> GenerateShortDraftUsecase:
        return self._usecase
```

この設計により、テスタビリティが向上し、将来的な機能拡張にも柔軟に対応できます。

## 実装手順

### 実装戦略

構成の末端（依存関係の最下層）から実装し、各段階でIntegration Testによる動作検証を行います。

**テスト方針**:
- `INTEGRATION_TEST=true` 環境変数が設定されている場合のみ、実際のLLM APIを使用したテストを実行
- CIでは実行せず、開発者のローカル環境でのみ実行
- モックを使った単体テストは優先度が低いため、Integration Test中心で進める

### 実装順序

```mermaid
graph TD
    A[1. データ構造] --> B[2. PromptBuilder]
    B --> C[3. API Clients]
    C --> D[4. DraftGenerator]
    D --> E[5. GenerateShortDraftUsecase]
    E --> F[6. main.py]

    C1[WhisperClient] --> D
    C2[ChatGPTClient] --> D
    B --> D
```

### Phase 1: データ構造の実装

**実装対象**:
- `TranscriptionSegment`
- `TranscriptionResult`
- `ShortVideoProposal`
- `DraftResult`
- `GenerateResult`

**実装ファイル**:
```
src/models/
├── __init__.py
├── transcription.py
├── draft.py
└── result.py
```

**テスト内容**:
- データクラスの基本的な生成・アクセステスト
- バリデーション機能のテスト

**完了条件**:
- 全データ構造が定義され、型チェック（mypy）が通る
- 基本的なデータ操作テストが通る

### Phase 2: PromptBuilderの実装

**実装対象**:
- `PromptBuilder`クラス
- `build_draft_prompt`メソッド

**実装ファイル**:
```
src/builders/
├── __init__.py
└── prompt_builder.py
```

**テスト内容**:
- サンプルの`TranscriptionResult`からプロンプト生成テスト
- プロンプトの形式・内容検証

**完了条件**:
- 文字起こし結果から適切なプロンプトが生成される
- プロンプトの品質が手動確認で妥当

### Phase 3: API Clientsの実装

#### 3-1: WhisperClientの実装

**実装対象**:
- `WhisperClient`クラス
- `transcribe`メソッド
- 音声抽出機能（ffmpeg連携）

**実装ファイル**:
```
src/clients/
├── __init__.py
└── whisper_client.py
```

**テスト内容** (`INTEGRATION_TEST=true`):
- 実際の音声ファイルでWhisper API呼び出しテスト
- タイムスタンプ付きセグメント生成テスト
- エラーハンドリング（不正ファイル、API障害）テスト

**完了条件**:
- 実際の音声ファイルから正確な文字起こしが取得できる
- タイムスタンプが適切に設定される

#### 3-2: ChatGPTClientの実装

**実装対象**:
- `ChatGPTClient`クラス
- `generate_draft`メソッド

**実装ファイル**:
```
src/clients/
└── chatgpt_client.py
```

**テスト内容** (`INTEGRATION_TEST=true`):
- 実際のプロンプトでChatGPT API呼び出しテスト
- 企画書形式の出力検証テスト
- レート制限・エラーハンドリングテスト

**完了条件**:
- 実際のプロンプトから構造化された企画書が生成される
- API呼び出しが安定して動作する

### Phase 4: DraftGeneratorの実装

**実装対象**:
- `DraftGenerator`クラス
- `generate_draft`メソッド
- 中間データ管理機能

**実装ファイル**:
```
src/service/
├── __init__.py
└── draft_generator.py
```

**テスト内容** (`INTEGRATION_TEST=true`):
- 実際の動画ファイルを使用したエンドツーエンドテスト
- WhisperClient → PromptBuilder → ChatGPTClientの連携テスト
- 中間ファイル（transcription.json）の生成・保存テスト

**完了条件**:
- 動画ファイルから企画書まで一貫した処理が動作する
- 中間データが適切に保存・管理される

### Phase 5: GenerateShortDraftUsecaseの実装

**実装対象**:
- `GenerateShortDraftUsecase`クラス
- `execute`メソッド
- 入力検証・出力ファイル管理

**実装ファイル**:
```
src/usecases/
├── __init__.py
└── generate_short_draft_usecase.py
```

**テスト内容** (`INTEGRATION_TEST=true`):
- 実際の動画ファイルでの全体フローテスト
- 出力ファイル（draft.md, subtitle.srt）の生成テスト
- エラーケース（存在しないファイル、権限エラー）テスト

**完了条件**:
- 動画ファイルから最終出力まで完全に動作する
- エラーハンドリングが適切に機能する

### Phase 6: main.pyの実装

**実装対象**:
- CLIインターフェース
- 引数解析・バリデーション
- DIコンテナの初期化

**実装ファイル**:
```
src/
└── main.py
```

**テスト内容** (`INTEGRATION_TEST=true`):
- コマンドライン実行での全体動作テスト
- 各種オプション・引数の動作確認
- 実際の使用シナリオでのテスト

**完了条件**:
- CLIとして完全に動作する
- ユーザビリティが確保されている

### 各Phase共通のテスト設定

#### テスト環境設定

**pytest設定** (`pytest.ini`):
```ini
[tool:pytest]
markers =
    integration: marks tests as integration tests (deselect with '-m "not integration"')
```

**テスト実行方法**:
```bash
# Integration Testを含む全テスト実行
INTEGRATION_TEST=true pytest

# Integration Testを除外して実行（CI用）
pytest -m "not integration"
```

#### 必要な環境変数

**開発・テスト用** (`.env.test`):
```
OPENAI_API_KEY=your_test_api_key
CHATGPT_MODEL=gpt-4
WHISPER_MODEL=whisper-1
INTEGRATION_TEST=true
```

#### テストデータ

**準備するテストファイル**:
```
tests/fixtures/
├── sample_video.mp4      # 短い動画ファイル（30秒程度）
├── sample_audio.wav      # 音声ファイル
└── expected_outputs/     # 期待される出力例
    ├── sample_draft.md
    └── sample_subtitle.srt
```

### 実装完了の判定基準

各Phaseで以下の条件を満たした場合に次のPhaseに進む：

1. **コード品質**:
   - mypy型チェックが通る
   - flake8リンターが通る
   - blackフォーマッターが適用されている

2. **テスト**:
   - Integration Testが全て通る
   - 手動での動作確認が完了している

3. **ドキュメント**:
   - 各クラス・メソッドにdocstringが記載されている
   - README.mdの該当部分が更新されている

### トラブルシューティング

#### API制限への対応
- OpenAI APIのレート制限に注意
- テスト実行時は適切な間隔を空ける
- API呼び出し失敗時のリトライ機能を実装

#### 開発効率化
- 各Phaseで中間出力を保存し、次回実行時に再利用
- テスト用の短い動画ファイルを使用
- ログ出力を充実させ、デバッグを容易にする

この実装手順により、依存関係の下位から段階的に実装し、各段階で実際のAPIを使用した動作検証を行うことで、確実に動作するシステムを構築できます。
